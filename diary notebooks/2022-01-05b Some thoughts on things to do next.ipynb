{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "automatic-basic",
   "metadata": {},
   "source": [
    "# 2022-01-05b Some thoughts on things to do next\n",
    "\n",
    "Given the pretty positive results shown in the notes from earlier today, here are some thoughts on what to do next:\n",
    "* Look a bit closer at retained parameterisations from the deterministic fits.\n",
    "    * The retained parameterisations for `oVAaoVAloBEooBEvoAI` are quite flat over the two `oBEo` parameters; I would like to understand why.\n",
    "    * For many of the parameters there is a spike of retained parameterisations at the upper edge of the parameter range. Why?\n",
    "* Add scripts for rerunning the parameterisations that are currently found to achieve short-stopping in the \"exaggerated early deceleration\" sense, to test whether they achieve it also in the \"exaggerated final stopping margin\" sense discussed and tested in the 2022-01-04 notes.\n",
    "    * Rather than saving out the metric analysis results from `do_2...` (which will be a quite large file), I can just rerun `do_2...` from within the first of the new scripts, to get the parameterisations in question.\n",
    "* Run through the entire rest of the pipeline on my computer:\n",
    "    * Probablistic fits with `oVA` as base, with 5 values per parameter. Looking at the parameterisations which achieved all four main deterministic criteria for `oVAaoVAloBEvoAI`, $T_\\delta$ = 40 s seems like a sensible choice (the average across those parameterisations is 42.5 s). \n",
    "    * ... All the way to predictions for the HIKER scenarios.\n",
    "        * Ideally also including the subsampling mentioned below to permit looking also at combined fits for `oVAaoVAloBEooBEvoAI` before going to ARC4.\n",
    "* If all is good, run the entire rest of the pipeline on ARC4.\n",
    "    * Based on some testing now, I should be able to run 10 values per parameter for the probabilistic fits with `oVA` as base. On my computer the execution time is about 12 s per parameterisation for the probablistic fits, and about 35 s per parameterisation for the combined fits. \n",
    "        * Probabilistic fits: For a three-parameter model, this will take about 1000 x 12 s = 12 ks = 3.3 h on my computer, or about 20 min on ARC4. So this part I should actually be able to do locally instead.\n",
    "        * Combined fits: Given 34 retained parameterisations for `oVAaoVAloBEvoAI`, and assuming that the highest number of retained parameters from the probabilistic fits will be about 12 % of parameterisations for the three-parameter models (as for `oVAoEAoSNv` in the 2021-12-05b notes), then we will have 120 retained probabilistic parameterisations, i.e., about 34 x 120 $\\approx$ 4000 combined parameterisations. Which will take 4000 x 35 s = 140 ks = 39 h on my computer, or about 4 h on ARC4. Given 3400 retained parameterisations for `oVAaoVAloBEooBEvoAI` we would be looking at 400 h on ARC4, so there I am thinking we can subsample the deterministic fits by a factor of 40 or so (for example randomly), to hit about 10 h on ARC4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
